{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-11-27 09:38:03.453409: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2017-11-27 09:38:03.453451: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2017-11-27 09:38:03.453456: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2017-11-27 09:38:03.453460: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1m\u001b[32mTest Passed\u001b[39m\u001b[22m"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using TensorFlow\n",
    "include(\"SimulEstControl/SSM.jl\")\n",
    "#need to include UKF stuff here probably"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pseudocode for DQN pipeline\n",
    "\n",
    "#Setup Neural Network: function createDQN()\n",
    "    #Input: State Measurement (possibly noisy), in R^6\n",
    "    #Output: Q values for actions in R^3, each discretized in {-k_i, 0, k_i}, in R^27\n",
    "    #Need placeholders for these variables, + a dict that maps an output index => u(t)\n",
    "    #Architecture: Let's try [64, 64, 256], fully connected, ReLu? Why not. Maybe add dropout.\n",
    "\n",
    "#Define op for updating target network weights\n",
    "\n",
    "#initialize DQN\n",
    "#initialize target network\n",
    "\n",
    "#Setup replay buffer\n",
    "    #Stores (s,a,r,s') tuples\n",
    "    #May need a method for sampling (to make life easier)\n",
    "    #May think through storing entire episodes, then provide a method for sampling random transitions across episodes\n",
    "        #(so we can reuse this for RNN training)\n",
    "\n",
    "#Training info\n",
    "    #Loss = mean_square(target_q,q)\n",
    "    #Optimizer = Adam (learning rate)\n",
    "\n",
    "#Wrap useful functions for self.sess.run()\n",
    "    #function train()\n",
    "    #function predict()\n",
    "    #function predictTarget()\n",
    "\n",
    "#Training\n",
    "    #initialize variables\n",
    "    #initialize graph writer\n",
    "    #initialize target weights\n",
    "    #initialize replay buffer\n",
    "    #for numTraining iters\n",
    "        #start @random state\n",
    "        #store running total of rewards\n",
    "        #for i=1:len(episode)\n",
    "            #take epsilon-greedy action via Q-net\n",
    "            #store transition in replay buffer\n",
    "            #if there are enough transitions in replay buffer\n",
    "                #sample minibatch of experiences from buffer\n",
    "                #calc target q's for each transition\n",
    "                #train DQN on minibatch\n",
    "            #if it has been 10,000 iters, update Q-network params (or can update via mixing factor)\n",
    "            #if state is terminal (i.e. at origin w/zero velocity)\n",
    "                #write zeros to the rest of the episode buffer\n",
    "                #print total episode reward\n",
    "    \n",
    "    #think of way to visualize training loss in TensorBoard\n",
    "\n",
    "#Testing\n",
    "    #roll out 100 episodes or so\n",
    "    #print average reward"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.1",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
